{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[[[1,2,3,4], [5,6,7,8]]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype = torch.float))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype = torch.float))\n",
    "        \n",
    "    def forward(self, x:torch.Tensor)-> torch.Tensor:\n",
    "        return self.weights * x + self.bias\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f998ddb2db0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in epochs:\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    y_pred_train = model(X_train)\n",
    "    \n",
    "    train_loss = loss_fn(y_pred_train, X_train)    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #Testing loop\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_preds = model(X_test)\n",
    "        test_loss = loss_fn(y_pred_test, X_test)\n",
    "    y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a model\n",
    "from pathlib import Path\n",
    "MODEL_PATH = Path('models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = 'model_name.pth'\n",
    "MODEL_SAVE_PATH = MODEL_PATH  / MODEL_NAME\n",
    "\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a model (CPU)\n",
    "\n",
    "loaded_model = LinearRegressionModel()\n",
    "\n",
    "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() == True else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegressionModelV2\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[-0.4869]])),\n",
       "             ('linear_layer.bias', tensor([0.5873]))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = LinearRegressionModelV2()\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.to(device)\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put data to gpu too\n",
    "X_train = X_train.to(device)\n",
    "and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X, y = make_circles(1000, noise=0.03, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.75424625,  0.23148074],\n",
       "        [-0.75615888,  0.15325888],\n",
       "        [-0.81539193,  0.17328203],\n",
       "        ...,\n",
       "        [-0.13690036, -0.81001183],\n",
       "        [ 0.67036156, -0.76750154],\n",
       "        [ 0.28105665,  0.96382443]]),\n",
       " array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75424625,  0.23148074],\n",
       "       [-0.75615888,  0.15325888],\n",
       "       [-0.81539193,  0.17328203],\n",
       "       ...,\n",
       "       [-0.13690036, -0.81001183],\n",
       "       [ 0.67036156, -0.76750154],\n",
       "       [ 0.28105665,  0.96382443]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"X1\":X[:, 0], \"X2\":X[:, 1], \"label\":y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754246</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756159</td>\n",
       "      <td>0.153259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.815392</td>\n",
       "      <td>0.173282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393731</td>\n",
       "      <td>0.692883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.442208</td>\n",
       "      <td>-0.896723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.244054</td>\n",
       "      <td>0.944125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.978655</td>\n",
       "      <td>-0.272373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.136900</td>\n",
       "      <td>-0.810012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.670362</td>\n",
       "      <td>-0.767502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.281057</td>\n",
       "      <td>0.963824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2  label\n",
       "0    0.754246  0.231481      1\n",
       "1   -0.756159  0.153259      1\n",
       "2   -0.815392  0.173282      1\n",
       "3   -0.393731  0.692883      1\n",
       "4    0.442208 -0.896723      0\n",
       "..        ...       ...    ...\n",
       "995  0.244054  0.944125      0\n",
       "996 -0.978655 -0.272373      0\n",
       "997 -0.136900 -0.810012      1\n",
       "998  0.670362 -0.767502      0\n",
       "999  0.281057  0.963824      0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float) \n",
    "y = torch.from_numpy(y).type(torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=2, out_features=5)\n",
    "        self.layer2 = nn.Linear(in_features=5, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer2(self.layer1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifierModel(\n",
       "  (layer1): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model = BinaryClassifierModel().to(device)\n",
    "binary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Sequential\n",
    "\n",
    "binary_model_2 = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=100, out_features=1),\n",
    "    \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-2.6694e-01,  5.8414e-01],\n",
       "                      [ 7.2337e-02, -5.2884e-01],\n",
       "                      [ 4.4278e-03, -5.4919e-01],\n",
       "                      [-1.5493e-01, -1.9444e-01],\n",
       "                      [ 6.1212e-01,  2.1902e-01],\n",
       "                      [-1.2330e-01,  1.1945e-01],\n",
       "                      [-2.0412e-01,  2.7782e-01],\n",
       "                      [ 2.7971e-01,  1.8989e-01],\n",
       "                      [-2.7561e-01,  6.0327e-01],\n",
       "                      [-1.0208e-01, -2.7529e-01],\n",
       "                      [ 4.4287e-01,  5.7633e-01],\n",
       "                      [ 7.0368e-01,  2.0949e-01],\n",
       "                      [-2.4105e-01,  3.5913e-01],\n",
       "                      [ 6.0667e-01, -6.9355e-01],\n",
       "                      [-8.7601e-02, -4.8222e-01],\n",
       "                      [ 1.3178e-01,  2.9245e-01],\n",
       "                      [-1.4608e-01, -5.9155e-02],\n",
       "                      [ 3.1828e-01, -1.1884e-01],\n",
       "                      [-5.9381e-01,  5.6578e-01],\n",
       "                      [-3.5590e-01, -7.7682e-02],\n",
       "                      [ 6.6699e-02, -4.2495e-02],\n",
       "                      [-6.6517e-01,  3.2442e-01],\n",
       "                      [-3.2119e-01, -3.6675e-01],\n",
       "                      [ 1.6894e-01, -3.6901e-01],\n",
       "                      [-3.2680e-01, -2.3826e-01],\n",
       "                      [-2.6564e-01, -2.9531e-01],\n",
       "                      [-1.9070e-01,  1.8376e-01],\n",
       "                      [-5.7220e-01, -4.2800e-01],\n",
       "                      [ 1.0318e-02,  9.8336e-02],\n",
       "                      [ 3.9053e-01, -4.9670e-01],\n",
       "                      [ 2.2571e-01,  4.0191e-01],\n",
       "                      [ 3.9263e-01, -6.5861e-01],\n",
       "                      [-2.6983e-01, -6.0780e-01],\n",
       "                      [-4.4747e-01,  3.9385e-01],\n",
       "                      [-1.0558e-01,  3.0032e-01],\n",
       "                      [-4.1508e-01,  1.0745e-01],\n",
       "                      [-4.2770e-01,  3.5348e-01],\n",
       "                      [-3.0927e-01, -1.7731e-01],\n",
       "                      [-6.1351e-01,  2.3359e-03],\n",
       "                      [ 6.7138e-01,  3.4321e-01],\n",
       "                      [-3.7727e-01,  9.5097e-03],\n",
       "                      [-7.7533e-02, -5.6927e-01],\n",
       "                      [ 5.5444e-01,  1.1399e-02],\n",
       "                      [ 1.4891e-01, -2.8555e-01],\n",
       "                      [-3.3087e-01,  1.1659e-01],\n",
       "                      [ 2.6143e-01,  1.5860e-01],\n",
       "                      [-3.4079e-01,  6.8653e-01],\n",
       "                      [-1.0409e-01, -4.3304e-01],\n",
       "                      [-3.3072e-01,  6.9609e-01],\n",
       "                      [ 3.4055e-05, -9.5986e-02],\n",
       "                      [-2.9427e-01, -1.8536e-01],\n",
       "                      [-5.9555e-01, -5.6193e-01],\n",
       "                      [ 4.1386e-01,  6.0489e-01],\n",
       "                      [ 6.7479e-01, -5.1049e-01],\n",
       "                      [ 3.8245e-01, -4.3768e-01],\n",
       "                      [ 4.2183e-01,  5.1022e-01],\n",
       "                      [ 5.4721e-01,  5.0915e-01],\n",
       "                      [ 4.4235e-01,  1.3763e-02],\n",
       "                      [ 3.2490e-01, -2.5298e-01],\n",
       "                      [ 3.0790e-01, -2.2727e-01],\n",
       "                      [-1.1873e-02, -6.1545e-01],\n",
       "                      [-1.8489e-01, -3.7185e-01],\n",
       "                      [-2.3852e-01, -4.5155e-01],\n",
       "                      [-6.3600e-01,  4.6044e-02],\n",
       "                      [ 4.5890e-01,  6.4400e-01],\n",
       "                      [ 4.1264e-01, -3.6652e-01],\n",
       "                      [-6.9934e-01,  2.6822e-01],\n",
       "                      [ 3.9620e-01, -6.0706e-01],\n",
       "                      [ 2.5356e-01,  5.9784e-01],\n",
       "                      [ 4.2834e-02, -4.2600e-01],\n",
       "                      [ 5.7974e-01,  3.0195e-01],\n",
       "                      [ 4.6825e-01, -4.7821e-01],\n",
       "                      [ 4.1150e-01, -4.8301e-01],\n",
       "                      [ 6.9968e-01, -2.9960e-01],\n",
       "                      [ 4.2608e-01,  1.4159e-01],\n",
       "                      [ 1.8739e-01, -1.0844e-01],\n",
       "                      [ 2.9043e-01, -2.9470e-01],\n",
       "                      [-6.6650e-01, -2.7167e-01],\n",
       "                      [ 5.5405e-01, -1.8616e-01],\n",
       "                      [ 2.2226e-01, -2.6144e-01],\n",
       "                      [ 5.3044e-01,  4.2320e-01],\n",
       "                      [ 2.4962e-01, -3.6145e-01],\n",
       "                      [-5.7780e-01,  2.6622e-02],\n",
       "                      [-4.1483e-01,  5.8138e-01],\n",
       "                      [-6.7951e-01,  3.1598e-01],\n",
       "                      [ 7.0492e-01,  3.5414e-01],\n",
       "                      [ 2.4111e-01, -6.8034e-01],\n",
       "                      [ 6.8016e-01, -1.2095e-01],\n",
       "                      [-6.6073e-01,  6.9803e-01],\n",
       "                      [-2.8774e-01, -5.0026e-02],\n",
       "                      [ 6.4720e-01, -4.9017e-01],\n",
       "                      [-5.0027e-01,  1.1499e-01],\n",
       "                      [-9.4649e-02,  1.6288e-01],\n",
       "                      [-5.9305e-01,  2.1147e-02],\n",
       "                      [-3.1449e-01, -3.4762e-01],\n",
       "                      [-6.4745e-01,  3.7492e-01],\n",
       "                      [ 1.3621e-01, -5.9782e-01],\n",
       "                      [ 5.6113e-01,  2.1328e-01],\n",
       "                      [ 1.3121e-01, -4.1517e-01],\n",
       "                      [ 1.0663e-01,  6.8133e-01]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.4850, -0.5507,  0.6455,  0.0548,  0.3401,  0.5492,  0.6028, -0.5512,\n",
       "                       0.6192, -0.4802,  0.0530, -0.4941, -0.1550, -0.0321, -0.0846, -0.1117,\n",
       "                       0.0558,  0.6975,  0.4108,  0.3956,  0.2830,  0.5474, -0.0326,  0.0562,\n",
       "                       0.1455, -0.6167, -0.5696,  0.0867, -0.2767, -0.0130, -0.1623,  0.1101,\n",
       "                       0.4601, -0.2345,  0.5663,  0.5583, -0.5427, -0.5460, -0.5721, -0.3875,\n",
       "                      -0.2753, -0.0532, -0.1720, -0.3573, -0.2246, -0.2558,  0.6937, -0.2621,\n",
       "                      -0.5063,  0.2939, -0.0408,  0.5413,  0.4418,  0.6496, -0.5179,  0.4546,\n",
       "                       0.5934, -0.3492,  0.6500,  0.5301,  0.0077,  0.3409, -0.2472, -0.6167,\n",
       "                       0.1787,  0.2108, -0.4621,  0.3429, -0.6040,  0.6086,  0.6848,  0.1925,\n",
       "                      -0.4437,  0.3441,  0.1205,  0.1923,  0.2324,  0.5384, -0.3039, -0.1591,\n",
       "                       0.1928,  0.0770,  0.5702, -0.3714, -0.0258,  0.1321, -0.1878,  0.4820,\n",
       "                       0.0773, -0.6535, -0.0766, -0.3207,  0.0687, -0.0822, -0.7014, -0.1289,\n",
       "                      -0.0677, -0.2085,  0.6497, -0.1543])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.0642,  0.0248, -0.0844,  0.0235,  0.0829, -0.0654, -0.0646,  0.0979,\n",
       "                        0.0804, -0.0558,  0.0602, -0.0128, -0.0986,  0.0075,  0.0323, -0.0300,\n",
       "                        0.0348, -0.0855,  0.0693,  0.0853,  0.0551,  0.0169,  0.0329, -0.0724,\n",
       "                       -0.0250, -0.0095, -0.0556, -0.0739,  0.0673,  0.0679, -0.0908,  0.0318,\n",
       "                        0.0407,  0.0950,  0.0579,  0.0919, -0.0327,  0.0700,  0.0813, -0.0944,\n",
       "                       -0.0803,  0.0202,  0.0546, -0.0497,  0.0110, -0.0001,  0.0253, -0.0537,\n",
       "                        0.0564,  0.0665, -0.0694,  0.0010,  0.0003,  0.0321,  0.0932,  0.0293,\n",
       "                       -0.0227,  0.0898, -0.0381, -0.0290,  0.0068, -0.0762,  0.0109, -0.0678,\n",
       "                        0.0103,  0.0096,  0.0138, -0.0843, -0.0950,  0.0460,  0.0858, -0.0887,\n",
       "                        0.0370, -0.0736,  0.0063,  0.0930,  0.0759, -0.0731,  0.0619,  0.0522,\n",
       "                       -0.0002,  0.0969, -0.0397, -0.0233, -0.0505,  0.0144,  0.0265,  0.0080,\n",
       "                       -0.0563, -0.0450,  0.0340, -0.0877, -0.0156, -0.0022, -0.0405,  0.0364,\n",
       "                        0.0064,  0.0702, -0.0089, -0.0631]])),\n",
       "             ('2.bias', tensor([0.0707]))])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=binary_model_2.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct/len(y_pred))\n",
    "    \n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6978, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.55 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(1.3205, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.7463, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.7338, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.8362, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.8151, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5275) Train Loss:  tensor(0.7413, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.56\n",
      "Test loss:  tensor(0.8075) Train Loss:  tensor(0.6877, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6028571428571429 Test Accuracy:  0.5266666666666666\n",
      "Test loss:  tensor(0.9575) Train Loss:  tensor(0.6757, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5214285714285715 Test Accuracy:  0.5533333333333333\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6905, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.52 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.7005, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6944, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6800, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.8608) Train Loss:  tensor(0.6679, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.4928571428571429 Test Accuracy:  0.59\n",
      "Test loss:  tensor(0.7041) Train Loss:  tensor(0.6616, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5642857142857143 Test Accuracy:  0.66\n",
      "Test loss:  tensor(0.6008) Train Loss:  tensor(0.6590, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6471428571428571 Test Accuracy:  0.6766666666666666\n",
      "Test loss:  tensor(0.5541) Train Loss:  tensor(0.6565, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7114285714285714 Test Accuracy:  0.7\n",
      "Test loss:  tensor(0.5908) Train Loss:  tensor(0.6516, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7471428571428571 Test Accuracy:  0.7033333333333334\n",
      "Test loss:  tensor(0.6775) Train Loss:  tensor(0.6444, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7528571428571429 Test Accuracy:  0.6666666666666666\n",
      "Test loss:  tensor(0.7208) Train Loss:  tensor(0.6371, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7114285714285714 Test Accuracy:  0.6966666666666667\n",
      "Test loss:  tensor(0.7575) Train Loss:  tensor(0.6326, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7042857142857143 Test Accuracy:  0.7\n",
      "Test loss:  tensor(0.7841) Train Loss:  tensor(0.6286, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6957142857142857 Test Accuracy:  0.6466666666666666\n",
      "Test loss:  tensor(0.8041) Train Loss:  tensor(0.6218, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6485714285714286 Test Accuracy:  0.61\n",
      "Test loss:  tensor(0.7775) Train Loss:  tensor(0.6127, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6342857142857142 Test Accuracy:  0.64\n",
      "Test loss:  tensor(0.7308) Train Loss:  tensor(0.6039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.67 Test Accuracy:  0.68\n",
      "Test loss:  tensor(0.7041) Train Loss:  tensor(0.5959, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7242857142857143 Test Accuracy:  0.7066666666666667\n",
      "Test loss:  tensor(0.6875) Train Loss:  tensor(0.5875, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7785714285714286 Test Accuracy:  0.73\n",
      "Test loss:  tensor(0.7008) Train Loss:  tensor(0.5776, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7885714285714286 Test Accuracy:  0.7166666666666667\n",
      "Test loss:  tensor(0.6741) Train Loss:  tensor(0.5663, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.8042857142857143 Test Accuracy:  0.7633333333333333\n",
      "Test loss:  tensor(0.6408) Train Loss:  tensor(0.5541, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.8242857142857143 Test Accuracy:  0.8266666666666667\n",
      "Test loss:  tensor(0.6141) Train Loss:  tensor(0.5428, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.85 Test Accuracy:  0.86\n",
      "Test loss:  tensor(0.5875) Train Loss:  tensor(0.5305, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.8657142857142858 Test Accuracy:  0.9\n",
      "Test loss:  tensor(0.5775) Train Loss:  tensor(0.5153, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9014285714285715 Test Accuracy:  0.9166666666666666\n",
      "Test loss:  tensor(0.5575) Train Loss:  tensor(0.4978, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9485714285714286 Test Accuracy:  0.93\n",
      "Test loss:  tensor(0.5341) Train Loss:  tensor(0.4803, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9642857142857143 Test Accuracy:  0.9533333333333334\n",
      "Test loss:  tensor(0.5341) Train Loss:  tensor(0.4628, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9714285714285714 Test Accuracy:  0.9633333333333334\n",
      "Test loss:  tensor(0.5541) Train Loss:  tensor(0.4429, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9842857142857143 Test Accuracy:  0.95\n",
      "Test loss:  tensor(0.5775) Train Loss:  tensor(0.4227, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9785714285714285 Test Accuracy:  0.9266666666666666\n",
      "Test loss:  tensor(0.5575) Train Loss:  tensor(0.4039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9742857142857143 Test Accuracy:  0.95\n",
      "Test loss:  tensor(0.5308) Train Loss:  tensor(0.3827, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9828571428571429 Test Accuracy:  0.98\n",
      "Test loss:  tensor(0.5275) Train Loss:  tensor(0.3604, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9885714285714285 Test Accuracy:  0.98\n",
      "Test loss:  tensor(0.5241) Train Loss:  tensor(0.3401, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9928571428571429 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5141) Train Loss:  tensor(0.3183, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9928571428571429 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5175) Train Loss:  tensor(0.2962, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5141) Train Loss:  tensor(0.2749, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.2535, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.99\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.2346, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9866666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.2150, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1969, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9971428571428571 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1802, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.99\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1650, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9866666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1506, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1375, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.99\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1255, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1146, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1048, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0957, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0879, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0804, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0739, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0676, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0624, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0576, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0532, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0495, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0460, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0431, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0403, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0377, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0355, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0334, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0316, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0299, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0284, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0270, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0257, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0245, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0234, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0224, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0214, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0206, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0198, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0191, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0184, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0178, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0172, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0167, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0162, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0157, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0153, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0149, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0145, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0141, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0137, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0134, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0131, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0128, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0125, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0122, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0119, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0117, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0115, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0112, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0110, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0108, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0106, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0104, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0102, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0100, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0099, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0097, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0096, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0094, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0092, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0091, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0090, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0088, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0087, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0086, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0084, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0083, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0082, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0081, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0080, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0079, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0078, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0077, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0076, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0075, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0074, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0073, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0072, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0071, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0070, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0069, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0068, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0068, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0067, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0066, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0065, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0065, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0064, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0063, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0062, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0062, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0061, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0060, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0060, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0059, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0059, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0058, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0057, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0057, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0056, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0056, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0055, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0054, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0054, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0053, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0053, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0052, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0052, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0051, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0051, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0050, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0050, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0048, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0048, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0047, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0047, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0046, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0046, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0046, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0045, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0045, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0043, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0043, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0043, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0041, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0041, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0038, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0038, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0038, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "X_train, X_test = X_train.to(device), X_test.to(device)\n",
    "y_train, y_test = y_train.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    y_logits = binary_model_2(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "    train_loss = loss_fn(y_logits, y_train)\n",
    "    acc_train = accuracy(y_pred=y_pred, y_true=y_train)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = binary_model_2(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        \n",
    "        test_loss = loss_fn(y_test, test_pred)\n",
    "        \n",
    "        acc_test = accuracy(y_pred=test_pred, y_true=y_test)\n",
    "        \n",
    "        print(\"Test loss: \", test_loss, \"Train Loss: \", train_loss, \"Train Accuracy: \", acc_train, \"Test Accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-class classification\n",
    "from sklearn.datasets import make_blobs\n",
    "X , y = make_blobs(n_samples=1000, n_features=2, centers=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-8.55503989,  7.06461794],\n",
       "        [-6.13753182, -6.58081701],\n",
       "        [-6.32130028, -6.8041042 ],\n",
       "        ...,\n",
       "        [ 3.69047995,  4.60555175],\n",
       "        [-7.48913939, -7.0670809 ],\n",
       "        [-9.40049578,  7.11430104]]),\n",
       " array([3, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 3, 0, 2, 2, 2, 0, 0, 0, 1, 1, 3,\n",
       "        3, 3, 1, 1, 0, 0, 2, 1, 2, 2, 2, 0, 0, 3, 2, 1, 3, 3, 1, 2, 1, 3,\n",
       "        1, 3, 0, 1, 3, 1, 2, 0, 1, 3, 0, 3, 0, 0, 0, 2, 2, 0, 2, 3, 1, 0,\n",
       "        2, 2, 1, 0, 3, 0, 1, 2, 1, 3, 1, 0, 1, 0, 2, 0, 0, 0, 1, 3, 2, 2,\n",
       "        0, 0, 0, 0, 1, 1, 3, 1, 3, 0, 1, 2, 1, 3, 3, 0, 3, 1, 1, 0, 2, 0,\n",
       "        3, 2, 1, 1, 1, 1, 2, 3, 2, 1, 0, 2, 3, 1, 3, 2, 1, 3, 2, 1, 0, 2,\n",
       "        1, 3, 1, 3, 0, 2, 1, 1, 0, 0, 3, 3, 3, 1, 1, 0, 0, 0, 0, 3, 2, 2,\n",
       "        0, 1, 0, 1, 1, 3, 2, 0, 1, 2, 0, 0, 1, 2, 3, 2, 1, 0, 0, 1, 0, 3,\n",
       "        2, 3, 2, 3, 1, 1, 0, 2, 0, 2, 1, 3, 0, 2, 1, 0, 1, 1, 0, 3, 2, 2,\n",
       "        2, 3, 0, 2, 1, 0, 1, 1, 2, 0, 1, 2, 2, 3, 2, 2, 1, 0, 2, 0, 3, 1,\n",
       "        3, 3, 2, 0, 3, 0, 1, 2, 2, 0, 0, 2, 0, 3, 2, 2, 3, 2, 2, 1, 2, 3,\n",
       "        2, 1, 3, 0, 1, 0, 1, 1, 1, 1, 3, 1, 1, 2, 0, 2, 2, 1, 1, 1, 3, 1,\n",
       "        3, 3, 2, 1, 0, 3, 1, 0, 1, 2, 0, 3, 1, 3, 2, 1, 3, 2, 3, 1, 2, 0,\n",
       "        0, 2, 0, 3, 3, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 3, 2, 3, 0, 2, 3, 1,\n",
       "        3, 3, 2, 3, 3, 1, 2, 3, 1, 0, 3, 3, 2, 2, 2, 1, 3, 2, 0, 2, 0, 0,\n",
       "        2, 2, 3, 3, 2, 0, 3, 1, 3, 1, 3, 2, 2, 1, 0, 1, 3, 3, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 2, 1, 0, 3, 1, 2, 2, 1, 3, 1, 3, 3, 3, 2, 1, 1, 1, 1,\n",
       "        0, 1, 0, 2, 1, 0, 2, 1, 3, 1, 1, 3, 0, 3, 2, 3, 2, 0, 3, 0, 3, 3,\n",
       "        2, 1, 1, 1, 0, 3, 0, 1, 1, 3, 1, 0, 0, 3, 1, 0, 3, 2, 3, 2, 2, 0,\n",
       "        3, 1, 0, 1, 0, 0, 0, 3, 2, 3, 1, 2, 0, 0, 3, 0, 3, 2, 3, 2, 2, 0,\n",
       "        3, 3, 3, 1, 0, 0, 1, 1, 2, 3, 3, 3, 1, 0, 3, 0, 2, 2, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 2, 2, 1, 0, 3, 1, 1, 3, 3, 2, 3, 0, 1, 0, 3, 1, 3, 2,\n",
       "        1, 0, 1, 2, 0, 1, 0, 2, 0, 3, 0, 3, 2, 2, 3, 3, 3, 0, 3, 0, 1, 2,\n",
       "        1, 1, 0, 1, 1, 2, 2, 0, 2, 1, 3, 0, 0, 0, 0, 1, 1, 1, 3, 1, 1, 2,\n",
       "        1, 0, 0, 1, 0, 3, 1, 0, 0, 1, 1, 3, 2, 3, 3, 0, 3, 1, 0, 1, 3, 3,\n",
       "        3, 0, 0, 0, 1, 1, 3, 2, 0, 0, 1, 0, 0, 0, 2, 3, 1, 1, 1, 0, 1, 2,\n",
       "        2, 2, 1, 3, 3, 3, 1, 0, 3, 3, 3, 0, 3, 1, 3, 2, 2, 3, 3, 3, 3, 0,\n",
       "        2, 2, 0, 2, 0, 1, 1, 1, 1, 0, 2, 3, 2, 0, 3, 0, 1, 3, 0, 2, 3, 2,\n",
       "        3, 1, 0, 3, 2, 1, 0, 1, 3, 2, 2, 3, 2, 1, 2, 2, 3, 0, 1, 2, 0, 2,\n",
       "        3, 1, 3, 2, 0, 2, 3, 0, 1, 2, 3, 3, 2, 2, 3, 3, 1, 3, 1, 0, 2, 0,\n",
       "        1, 3, 0, 3, 1, 2, 0, 0, 3, 0, 2, 2, 3, 0, 3, 3, 3, 1, 3, 0, 1, 2,\n",
       "        1, 1, 1, 1, 2, 1, 0, 0, 3, 1, 0, 1, 0, 2, 2, 3, 1, 3, 0, 2, 1, 2,\n",
       "        2, 3, 1, 3, 2, 2, 3, 3, 0, 0, 3, 3, 0, 2, 3, 1, 0, 2, 2, 3, 0, 0,\n",
       "        3, 2, 3, 0, 1, 3, 1, 1, 2, 0, 2, 3, 1, 2, 2, 3, 3, 2, 2, 0, 0, 2,\n",
       "        2, 2, 1, 0, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 0, 1, 2, 0, 0, 0, 3,\n",
       "        1, 2, 1, 0, 2, 3, 0, 0, 2, 3, 1, 2, 0, 1, 3, 0, 2, 3, 2, 2, 3, 0,\n",
       "        3, 2, 0, 0, 0, 3, 2, 3, 3, 1, 3, 1, 0, 1, 1, 3, 0, 1, 0, 0, 1, 3,\n",
       "        1, 3, 2, 3, 2, 0, 2, 3, 3, 1, 0, 1, 2, 2, 3, 0, 1, 2, 0, 3, 1, 0,\n",
       "        0, 3, 2, 1, 1, 1, 2, 2, 1, 2, 3, 3, 1, 2, 2, 3, 2, 2, 3, 1, 3, 3,\n",
       "        2, 2, 0, 3, 0, 2, 3, 0, 3, 2, 3, 0, 3, 2, 1, 1, 2, 2, 2, 0, 0, 0,\n",
       "        0, 3, 3, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 3, 3, 1, 1, 3, 3, 0,\n",
       "        1, 0, 1, 3, 0, 3, 0, 3, 0, 1, 2, 2, 2, 3, 0, 2, 1, 3, 3, 3, 2, 0,\n",
       "        1, 3, 1, 0, 0, 1, 2, 0, 0, 3, 1, 3, 3, 1, 0, 0, 3, 0, 2, 2, 2, 1,\n",
       "        1, 0, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 3, 0, 1, 2, 3, 1, 2, 0, 3, 1,\n",
       "        3, 2, 0, 2, 2, 0, 2, 3, 2, 3, 0, 3, 1, 1, 1, 2, 3, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 2, 1, 2, 0, 1, 2, 3]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float) \n",
    "y = torch.from_numpy(y).type(torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
