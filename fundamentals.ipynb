{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[[[1,2,3,4], [5,6,7,8]]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype = torch.float))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype = torch.float))\n",
    "        \n",
    "    def forward(self, x:torch.Tensor)-> torch.Tensor:\n",
    "        return self.weights * x + self.bias\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f998ddb2db0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in epochs:\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    y_pred_train = model(X_train)\n",
    "    \n",
    "    train_loss = loss_fn(y_pred_train, X_train)    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #Testing loop\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_preds = model(X_test)\n",
    "        test_loss = loss_fn(y_pred_test, X_test)\n",
    "    y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m MODEL_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m MODEL_SAVE_PATH \u001b[38;5;241m=\u001b[39m MODEL_PATH  \u001b[38;5;241m/\u001b[39m MODEL_NAME\n\u001b[0;32m----> 9\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(obj\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), f\u001b[38;5;241m=\u001b[39mMODEL_SAVE_PATH)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Saving a model\n",
    "from pathlib import Path\n",
    "MODEL_PATH = Path('models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = 'model_name.pth'\n",
    "MODEL_SAVE_PATH = MODEL_PATH  / MODEL_NAME\n",
    "\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a model (CPU)\n",
    "\n",
    "loaded_model = LinearRegressionModel()\n",
    "\n",
    "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() == True else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegressionModelV2\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[-0.4869]])),\n",
       "             ('linear_layer.bias', tensor([0.5873]))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = LinearRegressionModelV2()\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.to(device)\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put data to gpu too\n",
    "X_train = X_train.to(device)\n",
    "and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X, y = make_circles(1000, noise=0.03, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.75424625,  0.23148074],\n",
       "        [-0.75615888,  0.15325888],\n",
       "        [-0.81539193,  0.17328203],\n",
       "        ...,\n",
       "        [-0.13690036, -0.81001183],\n",
       "        [ 0.67036156, -0.76750154],\n",
       "        [ 0.28105665,  0.96382443]]),\n",
       " array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75424625,  0.23148074],\n",
       "       [-0.75615888,  0.15325888],\n",
       "       [-0.81539193,  0.17328203],\n",
       "       ...,\n",
       "       [-0.13690036, -0.81001183],\n",
       "       [ 0.67036156, -0.76750154],\n",
       "       [ 0.28105665,  0.96382443]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"X1\":X[:, 0], \"X2\":X[:, 1], \"label\":y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754246</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756159</td>\n",
       "      <td>0.153259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.815392</td>\n",
       "      <td>0.173282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393731</td>\n",
       "      <td>0.692883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.442208</td>\n",
       "      <td>-0.896723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.244054</td>\n",
       "      <td>0.944125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.978655</td>\n",
       "      <td>-0.272373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.136900</td>\n",
       "      <td>-0.810012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.670362</td>\n",
       "      <td>-0.767502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.281057</td>\n",
       "      <td>0.963824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2  label\n",
       "0    0.754246  0.231481      1\n",
       "1   -0.756159  0.153259      1\n",
       "2   -0.815392  0.173282      1\n",
       "3   -0.393731  0.692883      1\n",
       "4    0.442208 -0.896723      0\n",
       "..        ...       ...    ...\n",
       "995  0.244054  0.944125      0\n",
       "996 -0.978655 -0.272373      0\n",
       "997 -0.136900 -0.810012      1\n",
       "998  0.670362 -0.767502      0\n",
       "999  0.281057  0.963824      0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float) \n",
    "y = torch.from_numpy(y).type(torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=2, out_features=5)\n",
    "        self.layer2 = nn.Linear(in_features=5, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer2(self.layer1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifierModel(\n",
       "  (layer1): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model = BinaryClassifierModel().to(device)\n",
    "binary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Sequential\n",
    "\n",
    "binary_model_2 = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=100, out_features=1),\n",
    "    \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-2.6694e-01,  5.8414e-01],\n",
       "                      [ 7.2337e-02, -5.2884e-01],\n",
       "                      [ 4.4278e-03, -5.4919e-01],\n",
       "                      [-1.5493e-01, -1.9444e-01],\n",
       "                      [ 6.1212e-01,  2.1902e-01],\n",
       "                      [-1.2330e-01,  1.1945e-01],\n",
       "                      [-2.0412e-01,  2.7782e-01],\n",
       "                      [ 2.7971e-01,  1.8989e-01],\n",
       "                      [-2.7561e-01,  6.0327e-01],\n",
       "                      [-1.0208e-01, -2.7529e-01],\n",
       "                      [ 4.4287e-01,  5.7633e-01],\n",
       "                      [ 7.0368e-01,  2.0949e-01],\n",
       "                      [-2.4105e-01,  3.5913e-01],\n",
       "                      [ 6.0667e-01, -6.9355e-01],\n",
       "                      [-8.7601e-02, -4.8222e-01],\n",
       "                      [ 1.3178e-01,  2.9245e-01],\n",
       "                      [-1.4608e-01, -5.9155e-02],\n",
       "                      [ 3.1828e-01, -1.1884e-01],\n",
       "                      [-5.9381e-01,  5.6578e-01],\n",
       "                      [-3.5590e-01, -7.7682e-02],\n",
       "                      [ 6.6699e-02, -4.2495e-02],\n",
       "                      [-6.6517e-01,  3.2442e-01],\n",
       "                      [-3.2119e-01, -3.6675e-01],\n",
       "                      [ 1.6894e-01, -3.6901e-01],\n",
       "                      [-3.2680e-01, -2.3826e-01],\n",
       "                      [-2.6564e-01, -2.9531e-01],\n",
       "                      [-1.9070e-01,  1.8376e-01],\n",
       "                      [-5.7220e-01, -4.2800e-01],\n",
       "                      [ 1.0318e-02,  9.8336e-02],\n",
       "                      [ 3.9053e-01, -4.9670e-01],\n",
       "                      [ 2.2571e-01,  4.0191e-01],\n",
       "                      [ 3.9263e-01, -6.5861e-01],\n",
       "                      [-2.6983e-01, -6.0780e-01],\n",
       "                      [-4.4747e-01,  3.9385e-01],\n",
       "                      [-1.0558e-01,  3.0032e-01],\n",
       "                      [-4.1508e-01,  1.0745e-01],\n",
       "                      [-4.2770e-01,  3.5348e-01],\n",
       "                      [-3.0927e-01, -1.7731e-01],\n",
       "                      [-6.1351e-01,  2.3359e-03],\n",
       "                      [ 6.7138e-01,  3.4321e-01],\n",
       "                      [-3.7727e-01,  9.5097e-03],\n",
       "                      [-7.7533e-02, -5.6927e-01],\n",
       "                      [ 5.5444e-01,  1.1399e-02],\n",
       "                      [ 1.4891e-01, -2.8555e-01],\n",
       "                      [-3.3087e-01,  1.1659e-01],\n",
       "                      [ 2.6143e-01,  1.5860e-01],\n",
       "                      [-3.4079e-01,  6.8653e-01],\n",
       "                      [-1.0409e-01, -4.3304e-01],\n",
       "                      [-3.3072e-01,  6.9609e-01],\n",
       "                      [ 3.4055e-05, -9.5986e-02],\n",
       "                      [-2.9427e-01, -1.8536e-01],\n",
       "                      [-5.9555e-01, -5.6193e-01],\n",
       "                      [ 4.1386e-01,  6.0489e-01],\n",
       "                      [ 6.7479e-01, -5.1049e-01],\n",
       "                      [ 3.8245e-01, -4.3768e-01],\n",
       "                      [ 4.2183e-01,  5.1022e-01],\n",
       "                      [ 5.4721e-01,  5.0915e-01],\n",
       "                      [ 4.4235e-01,  1.3763e-02],\n",
       "                      [ 3.2490e-01, -2.5298e-01],\n",
       "                      [ 3.0790e-01, -2.2727e-01],\n",
       "                      [-1.1873e-02, -6.1545e-01],\n",
       "                      [-1.8489e-01, -3.7185e-01],\n",
       "                      [-2.3852e-01, -4.5155e-01],\n",
       "                      [-6.3600e-01,  4.6044e-02],\n",
       "                      [ 4.5890e-01,  6.4400e-01],\n",
       "                      [ 4.1264e-01, -3.6652e-01],\n",
       "                      [-6.9934e-01,  2.6822e-01],\n",
       "                      [ 3.9620e-01, -6.0706e-01],\n",
       "                      [ 2.5356e-01,  5.9784e-01],\n",
       "                      [ 4.2834e-02, -4.2600e-01],\n",
       "                      [ 5.7974e-01,  3.0195e-01],\n",
       "                      [ 4.6825e-01, -4.7821e-01],\n",
       "                      [ 4.1150e-01, -4.8301e-01],\n",
       "                      [ 6.9968e-01, -2.9960e-01],\n",
       "                      [ 4.2608e-01,  1.4159e-01],\n",
       "                      [ 1.8739e-01, -1.0844e-01],\n",
       "                      [ 2.9043e-01, -2.9470e-01],\n",
       "                      [-6.6650e-01, -2.7167e-01],\n",
       "                      [ 5.5405e-01, -1.8616e-01],\n",
       "                      [ 2.2226e-01, -2.6144e-01],\n",
       "                      [ 5.3044e-01,  4.2320e-01],\n",
       "                      [ 2.4962e-01, -3.6145e-01],\n",
       "                      [-5.7780e-01,  2.6622e-02],\n",
       "                      [-4.1483e-01,  5.8138e-01],\n",
       "                      [-6.7951e-01,  3.1598e-01],\n",
       "                      [ 7.0492e-01,  3.5414e-01],\n",
       "                      [ 2.4111e-01, -6.8034e-01],\n",
       "                      [ 6.8016e-01, -1.2095e-01],\n",
       "                      [-6.6073e-01,  6.9803e-01],\n",
       "                      [-2.8774e-01, -5.0026e-02],\n",
       "                      [ 6.4720e-01, -4.9017e-01],\n",
       "                      [-5.0027e-01,  1.1499e-01],\n",
       "                      [-9.4649e-02,  1.6288e-01],\n",
       "                      [-5.9305e-01,  2.1147e-02],\n",
       "                      [-3.1449e-01, -3.4762e-01],\n",
       "                      [-6.4745e-01,  3.7492e-01],\n",
       "                      [ 1.3621e-01, -5.9782e-01],\n",
       "                      [ 5.6113e-01,  2.1328e-01],\n",
       "                      [ 1.3121e-01, -4.1517e-01],\n",
       "                      [ 1.0663e-01,  6.8133e-01]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.4850, -0.5507,  0.6455,  0.0548,  0.3401,  0.5492,  0.6028, -0.5512,\n",
       "                       0.6192, -0.4802,  0.0530, -0.4941, -0.1550, -0.0321, -0.0846, -0.1117,\n",
       "                       0.0558,  0.6975,  0.4108,  0.3956,  0.2830,  0.5474, -0.0326,  0.0562,\n",
       "                       0.1455, -0.6167, -0.5696,  0.0867, -0.2767, -0.0130, -0.1623,  0.1101,\n",
       "                       0.4601, -0.2345,  0.5663,  0.5583, -0.5427, -0.5460, -0.5721, -0.3875,\n",
       "                      -0.2753, -0.0532, -0.1720, -0.3573, -0.2246, -0.2558,  0.6937, -0.2621,\n",
       "                      -0.5063,  0.2939, -0.0408,  0.5413,  0.4418,  0.6496, -0.5179,  0.4546,\n",
       "                       0.5934, -0.3492,  0.6500,  0.5301,  0.0077,  0.3409, -0.2472, -0.6167,\n",
       "                       0.1787,  0.2108, -0.4621,  0.3429, -0.6040,  0.6086,  0.6848,  0.1925,\n",
       "                      -0.4437,  0.3441,  0.1205,  0.1923,  0.2324,  0.5384, -0.3039, -0.1591,\n",
       "                       0.1928,  0.0770,  0.5702, -0.3714, -0.0258,  0.1321, -0.1878,  0.4820,\n",
       "                       0.0773, -0.6535, -0.0766, -0.3207,  0.0687, -0.0822, -0.7014, -0.1289,\n",
       "                      -0.0677, -0.2085,  0.6497, -0.1543])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.0642,  0.0248, -0.0844,  0.0235,  0.0829, -0.0654, -0.0646,  0.0979,\n",
       "                        0.0804, -0.0558,  0.0602, -0.0128, -0.0986,  0.0075,  0.0323, -0.0300,\n",
       "                        0.0348, -0.0855,  0.0693,  0.0853,  0.0551,  0.0169,  0.0329, -0.0724,\n",
       "                       -0.0250, -0.0095, -0.0556, -0.0739,  0.0673,  0.0679, -0.0908,  0.0318,\n",
       "                        0.0407,  0.0950,  0.0579,  0.0919, -0.0327,  0.0700,  0.0813, -0.0944,\n",
       "                       -0.0803,  0.0202,  0.0546, -0.0497,  0.0110, -0.0001,  0.0253, -0.0537,\n",
       "                        0.0564,  0.0665, -0.0694,  0.0010,  0.0003,  0.0321,  0.0932,  0.0293,\n",
       "                       -0.0227,  0.0898, -0.0381, -0.0290,  0.0068, -0.0762,  0.0109, -0.0678,\n",
       "                        0.0103,  0.0096,  0.0138, -0.0843, -0.0950,  0.0460,  0.0858, -0.0887,\n",
       "                        0.0370, -0.0736,  0.0063,  0.0930,  0.0759, -0.0731,  0.0619,  0.0522,\n",
       "                       -0.0002,  0.0969, -0.0397, -0.0233, -0.0505,  0.0144,  0.0265,  0.0080,\n",
       "                       -0.0563, -0.0450,  0.0340, -0.0877, -0.0156, -0.0022, -0.0405,  0.0364,\n",
       "                        0.0064,  0.0702, -0.0089, -0.0631]])),\n",
       "             ('2.bias', tensor([0.0707]))])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=binary_model_2.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct/len(y_pred))\n",
    "    \n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6978, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.55 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(1.3205, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.7463, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.7338, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.8362, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.8151, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.48\n",
      "Test loss:  tensor(0.5275) Train Loss:  tensor(0.7413, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5085714285714286 Test Accuracy:  0.56\n",
      "Test loss:  tensor(0.8075) Train Loss:  tensor(0.6877, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6028571428571429 Test Accuracy:  0.5266666666666666\n",
      "Test loss:  tensor(0.9575) Train Loss:  tensor(0.6757, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5214285714285715 Test Accuracy:  0.5533333333333333\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6905, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.52 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.7005, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6944, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.9908) Train Loss:  tensor(0.6800, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.49142857142857144 Test Accuracy:  0.52\n",
      "Test loss:  tensor(0.8608) Train Loss:  tensor(0.6679, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.4928571428571429 Test Accuracy:  0.59\n",
      "Test loss:  tensor(0.7041) Train Loss:  tensor(0.6616, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.5642857142857143 Test Accuracy:  0.66\n",
      "Test loss:  tensor(0.6008) Train Loss:  tensor(0.6590, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6471428571428571 Test Accuracy:  0.6766666666666666\n",
      "Test loss:  tensor(0.5541) Train Loss:  tensor(0.6565, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7114285714285714 Test Accuracy:  0.7\n",
      "Test loss:  tensor(0.5908) Train Loss:  tensor(0.6516, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7471428571428571 Test Accuracy:  0.7033333333333334\n",
      "Test loss:  tensor(0.6775) Train Loss:  tensor(0.6444, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7528571428571429 Test Accuracy:  0.6666666666666666\n",
      "Test loss:  tensor(0.7208) Train Loss:  tensor(0.6371, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7114285714285714 Test Accuracy:  0.6966666666666667\n",
      "Test loss:  tensor(0.7575) Train Loss:  tensor(0.6326, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7042857142857143 Test Accuracy:  0.7\n",
      "Test loss:  tensor(0.7841) Train Loss:  tensor(0.6286, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6957142857142857 Test Accuracy:  0.6466666666666666\n",
      "Test loss:  tensor(0.8041) Train Loss:  tensor(0.6218, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6485714285714286 Test Accuracy:  0.61\n",
      "Test loss:  tensor(0.7775) Train Loss:  tensor(0.6127, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.6342857142857142 Test Accuracy:  0.64\n",
      "Test loss:  tensor(0.7308) Train Loss:  tensor(0.6039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.67 Test Accuracy:  0.68\n",
      "Test loss:  tensor(0.7041) Train Loss:  tensor(0.5959, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7242857142857143 Test Accuracy:  0.7066666666666667\n",
      "Test loss:  tensor(0.6875) Train Loss:  tensor(0.5875, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7785714285714286 Test Accuracy:  0.73\n",
      "Test loss:  tensor(0.7008) Train Loss:  tensor(0.5776, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.7885714285714286 Test Accuracy:  0.7166666666666667\n",
      "Test loss:  tensor(0.6741) Train Loss:  tensor(0.5663, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.8042857142857143 Test Accuracy:  0.7633333333333333\n",
      "Test loss:  tensor(0.6408) Train Loss:  tensor(0.5541, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.8242857142857143 Test Accuracy:  0.8266666666666667\n",
      "Test loss:  tensor(0.6141) Train Loss:  tensor(0.5428, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.85 Test Accuracy:  0.86\n",
      "Test loss:  tensor(0.5875) Train Loss:  tensor(0.5305, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.8657142857142858 Test Accuracy:  0.9\n",
      "Test loss:  tensor(0.5775) Train Loss:  tensor(0.5153, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9014285714285715 Test Accuracy:  0.9166666666666666\n",
      "Test loss:  tensor(0.5575) Train Loss:  tensor(0.4978, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9485714285714286 Test Accuracy:  0.93\n",
      "Test loss:  tensor(0.5341) Train Loss:  tensor(0.4803, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9642857142857143 Test Accuracy:  0.9533333333333334\n",
      "Test loss:  tensor(0.5341) Train Loss:  tensor(0.4628, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9714285714285714 Test Accuracy:  0.9633333333333334\n",
      "Test loss:  tensor(0.5541) Train Loss:  tensor(0.4429, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9842857142857143 Test Accuracy:  0.95\n",
      "Test loss:  tensor(0.5775) Train Loss:  tensor(0.4227, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9785714285714285 Test Accuracy:  0.9266666666666666\n",
      "Test loss:  tensor(0.5575) Train Loss:  tensor(0.4039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9742857142857143 Test Accuracy:  0.95\n",
      "Test loss:  tensor(0.5308) Train Loss:  tensor(0.3827, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9828571428571429 Test Accuracy:  0.98\n",
      "Test loss:  tensor(0.5275) Train Loss:  tensor(0.3604, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9885714285714285 Test Accuracy:  0.98\n",
      "Test loss:  tensor(0.5241) Train Loss:  tensor(0.3401, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9928571428571429 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5141) Train Loss:  tensor(0.3183, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9928571428571429 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5175) Train Loss:  tensor(0.2962, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5141) Train Loss:  tensor(0.2749, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.2535, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.99\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.2346, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9866666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.2150, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1969, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9971428571428571 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1802, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.99\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1650, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9866666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1506, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1375, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.99\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1255, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1146, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9833333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.1048, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0957, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0879, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0804, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0739, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9933333333333333\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0676, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0624, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0576, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0532, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0495, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0460, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0431, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0403, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0377, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0355, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0334, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0316, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  0.9985714285714286 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0299, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0284, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0270, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0257, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0245, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0234, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0224, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0214, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0206, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0198, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0191, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0184, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0178, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0172, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0167, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0162, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0157, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0153, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0149, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0145, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0141, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0137, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0134, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0131, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0128, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0125, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0122, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0119, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0117, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0115, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0112, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0110, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0108, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0106, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0104, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0102, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0100, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0099, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0097, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0096, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0094, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0092, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0091, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0090, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0088, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0087, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0086, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0084, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0083, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0082, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0081, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0080, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0079, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0078, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0077, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0076, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0075, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0074, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0073, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0072, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0071, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0070, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0069, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0068, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0068, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0067, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0066, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0065, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0065, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0064, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0063, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0062, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0062, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0061, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0060, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0060, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0059, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0059, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0058, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0057, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0057, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0056, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0056, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0055, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0054, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0054, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0053, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0053, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0052, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0052, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0051, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0051, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0050, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0050, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0049, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0048, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0048, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0047, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0047, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0046, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0046, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0046, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0045, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0045, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0044, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0043, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0043, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0043, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0041, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0041, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0040, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0039, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0038, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0038, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0038, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0037, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0036, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0035, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0033, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0032, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0030, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0029, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0027, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0026, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0025, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0024, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0022, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0021, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0019, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0016, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0010, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n",
      "Test loss:  tensor(0.5108) Train Loss:  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) Train Accuracy:  1.0 Test Accuracy:  0.9966666666666667\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "X_train, X_test = X_train.to(device), X_test.to(device)\n",
    "y_train, y_test = y_train.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    y_logits = binary_model_2(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "    train_loss = loss_fn(y_logits, y_train)\n",
    "    acc_train = accuracy(y_pred=y_pred, y_true=y_train)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = binary_model_2(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        \n",
    "        test_loss = loss_fn(y_test, test_pred)\n",
    "        \n",
    "        acc_test = accuracy(y_pred=test_pred, y_true=y_test)\n",
    "        \n",
    "        print(\"Test loss: \", test_loss, \"Train Loss: \", train_loss, \"Train Accuracy: \", acc_train, \"Test Accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-class classification\n",
    "from sklearn.datasets import make_blobs\n",
    "X , y = make_blobs(n_samples=1000, n_features=2, centers=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-8.55503989,  7.06461794],\n",
       "        [-6.13753182, -6.58081701],\n",
       "        [-6.32130028, -6.8041042 ],\n",
       "        ...,\n",
       "        [ 3.69047995,  4.60555175],\n",
       "        [-7.48913939, -7.0670809 ],\n",
       "        [-9.40049578,  7.11430104]]),\n",
       " array([3, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 3, 0, 2, 2, 2, 0, 0, 0, 1, 1, 3,\n",
       "        3, 3, 1, 1, 0, 0, 2, 1, 2, 2, 2, 0, 0, 3, 2, 1, 3, 3, 1, 2, 1, 3,\n",
       "        1, 3, 0, 1, 3, 1, 2, 0, 1, 3, 0, 3, 0, 0, 0, 2, 2, 0, 2, 3, 1, 0,\n",
       "        2, 2, 1, 0, 3, 0, 1, 2, 1, 3, 1, 0, 1, 0, 2, 0, 0, 0, 1, 3, 2, 2,\n",
       "        0, 0, 0, 0, 1, 1, 3, 1, 3, 0, 1, 2, 1, 3, 3, 0, 3, 1, 1, 0, 2, 0,\n",
       "        3, 2, 1, 1, 1, 1, 2, 3, 2, 1, 0, 2, 3, 1, 3, 2, 1, 3, 2, 1, 0, 2,\n",
       "        1, 3, 1, 3, 0, 2, 1, 1, 0, 0, 3, 3, 3, 1, 1, 0, 0, 0, 0, 3, 2, 2,\n",
       "        0, 1, 0, 1, 1, 3, 2, 0, 1, 2, 0, 0, 1, 2, 3, 2, 1, 0, 0, 1, 0, 3,\n",
       "        2, 3, 2, 3, 1, 1, 0, 2, 0, 2, 1, 3, 0, 2, 1, 0, 1, 1, 0, 3, 2, 2,\n",
       "        2, 3, 0, 2, 1, 0, 1, 1, 2, 0, 1, 2, 2, 3, 2, 2, 1, 0, 2, 0, 3, 1,\n",
       "        3, 3, 2, 0, 3, 0, 1, 2, 2, 0, 0, 2, 0, 3, 2, 2, 3, 2, 2, 1, 2, 3,\n",
       "        2, 1, 3, 0, 1, 0, 1, 1, 1, 1, 3, 1, 1, 2, 0, 2, 2, 1, 1, 1, 3, 1,\n",
       "        3, 3, 2, 1, 0, 3, 1, 0, 1, 2, 0, 3, 1, 3, 2, 1, 3, 2, 3, 1, 2, 0,\n",
       "        0, 2, 0, 3, 3, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 3, 2, 3, 0, 2, 3, 1,\n",
       "        3, 3, 2, 3, 3, 1, 2, 3, 1, 0, 3, 3, 2, 2, 2, 1, 3, 2, 0, 2, 0, 0,\n",
       "        2, 2, 3, 3, 2, 0, 3, 1, 3, 1, 3, 2, 2, 1, 0, 1, 3, 3, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 2, 1, 0, 3, 1, 2, 2, 1, 3, 1, 3, 3, 3, 2, 1, 1, 1, 1,\n",
       "        0, 1, 0, 2, 1, 0, 2, 1, 3, 1, 1, 3, 0, 3, 2, 3, 2, 0, 3, 0, 3, 3,\n",
       "        2, 1, 1, 1, 0, 3, 0, 1, 1, 3, 1, 0, 0, 3, 1, 0, 3, 2, 3, 2, 2, 0,\n",
       "        3, 1, 0, 1, 0, 0, 0, 3, 2, 3, 1, 2, 0, 0, 3, 0, 3, 2, 3, 2, 2, 0,\n",
       "        3, 3, 3, 1, 0, 0, 1, 1, 2, 3, 3, 3, 1, 0, 3, 0, 2, 2, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 2, 2, 1, 0, 3, 1, 1, 3, 3, 2, 3, 0, 1, 0, 3, 1, 3, 2,\n",
       "        1, 0, 1, 2, 0, 1, 0, 2, 0, 3, 0, 3, 2, 2, 3, 3, 3, 0, 3, 0, 1, 2,\n",
       "        1, 1, 0, 1, 1, 2, 2, 0, 2, 1, 3, 0, 0, 0, 0, 1, 1, 1, 3, 1, 1, 2,\n",
       "        1, 0, 0, 1, 0, 3, 1, 0, 0, 1, 1, 3, 2, 3, 3, 0, 3, 1, 0, 1, 3, 3,\n",
       "        3, 0, 0, 0, 1, 1, 3, 2, 0, 0, 1, 0, 0, 0, 2, 3, 1, 1, 1, 0, 1, 2,\n",
       "        2, 2, 1, 3, 3, 3, 1, 0, 3, 3, 3, 0, 3, 1, 3, 2, 2, 3, 3, 3, 3, 0,\n",
       "        2, 2, 0, 2, 0, 1, 1, 1, 1, 0, 2, 3, 2, 0, 3, 0, 1, 3, 0, 2, 3, 2,\n",
       "        3, 1, 0, 3, 2, 1, 0, 1, 3, 2, 2, 3, 2, 1, 2, 2, 3, 0, 1, 2, 0, 2,\n",
       "        3, 1, 3, 2, 0, 2, 3, 0, 1, 2, 3, 3, 2, 2, 3, 3, 1, 3, 1, 0, 2, 0,\n",
       "        1, 3, 0, 3, 1, 2, 0, 0, 3, 0, 2, 2, 3, 0, 3, 3, 3, 1, 3, 0, 1, 2,\n",
       "        1, 1, 1, 1, 2, 1, 0, 0, 3, 1, 0, 1, 0, 2, 2, 3, 1, 3, 0, 2, 1, 2,\n",
       "        2, 3, 1, 3, 2, 2, 3, 3, 0, 0, 3, 3, 0, 2, 3, 1, 0, 2, 2, 3, 0, 0,\n",
       "        3, 2, 3, 0, 1, 3, 1, 1, 2, 0, 2, 3, 1, 2, 2, 3, 3, 2, 2, 0, 0, 2,\n",
       "        2, 2, 1, 0, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 0, 1, 2, 0, 0, 0, 3,\n",
       "        1, 2, 1, 0, 2, 3, 0, 0, 2, 3, 1, 2, 0, 1, 3, 0, 2, 3, 2, 2, 3, 0,\n",
       "        3, 2, 0, 0, 0, 3, 2, 3, 3, 1, 3, 1, 0, 1, 1, 3, 0, 1, 0, 0, 1, 3,\n",
       "        1, 3, 2, 3, 2, 0, 2, 3, 3, 1, 0, 1, 2, 2, 3, 0, 1, 2, 0, 3, 1, 0,\n",
       "        0, 3, 2, 1, 1, 1, 2, 2, 1, 2, 3, 3, 1, 2, 2, 3, 2, 2, 3, 1, 3, 3,\n",
       "        2, 2, 0, 3, 0, 2, 3, 0, 3, 2, 3, 0, 3, 2, 1, 1, 2, 2, 2, 0, 0, 0,\n",
       "        0, 3, 3, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 3, 3, 1, 1, 3, 3, 0,\n",
       "        1, 0, 1, 3, 0, 3, 0, 3, 0, 1, 2, 2, 2, 3, 0, 2, 1, 3, 3, 3, 2, 0,\n",
       "        1, 3, 1, 0, 0, 1, 2, 0, 0, 3, 1, 3, 3, 1, 0, 0, 3, 0, 2, 2, 2, 1,\n",
       "        1, 0, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 3, 0, 1, 2, 3, 1, 2, 0, 3, 1,\n",
       "        3, 2, 0, 2, 2, 0, 2, 3, 2, 3, 0, 3, 1, 1, 1, 2, 3, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 2, 1, 2, 0, 1, 2, 3]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float) \n",
    "y = torch.from_numpy(y).type(torch.LongTensor) # It needs the class indices to be integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same model arhcitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=binary_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get logits\n",
    "y_preds_blobs = torch.softmax(y_logits, dim=1)\n",
    "y_pred = torch.argmax(y_preds_blobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvrajsingh/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision \n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_to_id = train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV2(nn.Module):\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "       \n",
    "        nn.Conv2d(in_channels=input_shape, \n",
    "                  out_channels=hidden_units,\n",
    "                  kernel_size=3,\n",
    "                  stride=1,\n",
    "                  padding=1), \n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=hidden_units,\n",
    "                  out_channels=hidden_units,\n",
    "                  kernel_size=3,\n",
    "                  stride=1,\n",
    "                  padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=hidden_units,\n",
    "                  out_channels=hidden_units,\n",
    "                  kernel_size=3,\n",
    "                  stride=1,\n",
    "                  padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=hidden_units,\n",
    "                  out_channels=hidden_units,\n",
    "                  kernel_size=3,\n",
    "                  stride=1,\n",
    "                  padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=hidden_units*256, # there's a trick to calculating this...\n",
    "                  out_features=output_shape)\n",
    "    )\n",
    "#the trick\n",
    "# img_batch, img_label = next(iter(train_dataloader))\n",
    "# model_cnn(img_batch)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv_block_1(x)\n",
    "    # print(f\"Output shape of conv_block_1: {x.shape}\")\n",
    "    x = self.conv_block_2(x) \n",
    "    # print(f\"Output shape of conv_block_2: {x.shape}\")\n",
    "    x = self.classifier(x)\n",
    "    # print(f\"Output shape of classifier: {x.shape}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1185, 0.0484, 0.1040],\n",
       "        [0.1317, 0.0532, 0.1127],\n",
       "        [0.1262, 0.0549, 0.1190],\n",
       "        [0.1190, 0.0458, 0.1125],\n",
       "        [0.1246, 0.0464, 0.1048],\n",
       "        [0.0968, 0.0576, 0.1049],\n",
       "        [0.1244, 0.0483, 0.1133],\n",
       "        [0.1143, 0.0298, 0.1039],\n",
       "        [0.1374, 0.0598, 0.1148],\n",
       "        [0.1304, 0.0462, 0.1198],\n",
       "        [0.1240, 0.0435, 0.1277],\n",
       "        [0.1348, 0.0443, 0.1082],\n",
       "        [0.1281, 0.0490, 0.1145],\n",
       "        [0.1116, 0.0493, 0.1000],\n",
       "        [0.1308, 0.0484, 0.1193],\n",
       "        [0.1340, 0.0492, 0.1110],\n",
       "        [0.1207, 0.0448, 0.1105],\n",
       "        [0.0963, 0.0233, 0.0996],\n",
       "        [0.1189, 0.0524, 0.1086],\n",
       "        [0.1103, 0.0422, 0.1073],\n",
       "        [0.1144, 0.0562, 0.1111],\n",
       "        [0.1298, 0.0567, 0.1137],\n",
       "        [0.1296, 0.0677, 0.1194],\n",
       "        [0.1304, 0.0468, 0.1030],\n",
       "        [0.1057, 0.0404, 0.0991],\n",
       "        [0.1023, 0.0374, 0.0986],\n",
       "        [0.1062, 0.0411, 0.1037],\n",
       "        [0.1377, 0.0538, 0.1253],\n",
       "        [0.1348, 0.0575, 0.1147],\n",
       "        [0.1276, 0.0330, 0.1180],\n",
       "        [0.1249, 0.0512, 0.1126],\n",
       "        [0.1474, 0.0492, 0.1211]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_cnn \u001b[38;5;241m=\u001b[39m FashionMNISTModelV2(input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, output_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mclass_names\u001b[49m), hidden_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      2\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model_cnn\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "model_cnn = FashionMNISTModelV2(input_shape=3, output_shape=len(class_names), hidden_units=100)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m)\n\u001b[1;32m      2\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[1;32m      3\u001b[0m images, labels\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_dataloader)\n",
    "images, labels = next(data_iter)\n",
    "images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.07421875 Test loss:  tensor(548671.6875)\n",
      "Test accuracy:  0.09765625 Test loss:  tensor(173.7873)\n",
      "Test accuracy:  0.09765625 Test loss:  tensor(70.1312)\n",
      "Test accuracy:  0.203125 Test loss:  tensor(7.9468)\n",
      "Test accuracy:  0.203125 Test loss:  tensor(1.1196)\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader_augmented):\n",
    "        model_cnn.train()\n",
    "        \n",
    "        y_pred = model_cnn(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_dataloader)\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model_cnn.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader_augmented:\n",
    "            test_pred = model_cnn(X_test)\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            probs = torch.softmax(test_pred, dim=1)\n",
    "            test_acc += accuracy(y_pred=torch.argmax(probs, dim=1), y_true=y_test)\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(train_dataloader)\n",
    "        \n",
    "    print(\"Test accuracy: \", test_acc, \"Test loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2/pizza_steak_sushi directory already exists... skipping download\n",
      "Downloading pizza, steak, suhsi data...\n",
      "Unzipping pizza, steak and sushi data...\n"
     ]
    }
   ],
   "source": [
    "#Custom Datasets\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to a data folder\n",
    "data_path = Path(\"data2/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it...\n",
    "if image_path.is_dir():\n",
    "  print(f\"{image_path} directory already exists... skipping download\")\n",
    "else: \n",
    "  print(f\"{image_path} does not exist, creating one...\")\n",
    "  image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download pizza, steak and suhsi data\n",
    "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "  print(\"Downloading pizza, steak, suhsi data...\")\n",
    "  f.write(request.content)\n",
    "\n",
    "# Unzip pizza, steak, sushi data\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "  print(\"Unzipping pizza, steak and sushi data...\")\n",
    "  zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data2/pizza_steak_sushi/train'),\n",
       " PosixPath('data2/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Setup train and testing paths\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(train_dir, transform=data_transform, target_transform=None)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=data_transform, target_transform=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(dataset\u001b[38;5;241m=\u001b[39mtrain_data, num_workers\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mcpu_count(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, num_workers=os.cpu_count(), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset=test_data, num_workers=os.cpu_count(), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting summary\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FashionMNISTModelV2                      [1, 3]                    --\n",
       "â”œâ”€Sequential: 1-1                        [1, 10, 32, 32]           --\n",
       "â”‚    â””â”€Conv2d: 2-1                       [1, 10, 64, 64]           280\n",
       "â”‚    â””â”€ReLU: 2-2                         [1, 10, 64, 64]           --\n",
       "â”‚    â””â”€Conv2d: 2-3                       [1, 10, 64, 64]           910\n",
       "â”‚    â””â”€ReLU: 2-4                         [1, 10, 64, 64]           --\n",
       "â”‚    â””â”€MaxPool2d: 2-5                    [1, 10, 32, 32]           --\n",
       "â”œâ”€Sequential: 1-2                        [1, 10, 16, 16]           --\n",
       "â”‚    â””â”€Conv2d: 2-6                       [1, 10, 32, 32]           910\n",
       "â”‚    â””â”€ReLU: 2-7                         [1, 10, 32, 32]           --\n",
       "â”‚    â””â”€Conv2d: 2-8                       [1, 10, 32, 32]           910\n",
       "â”‚    â””â”€ReLU: 2-9                         [1, 10, 32, 32]           --\n",
       "â”‚    â””â”€MaxPool2d: 2-10                   [1, 10, 16, 16]           --\n",
       "â”œâ”€Sequential: 1-3                        [1, 3]                    --\n",
       "â”‚    â””â”€Flatten: 2-11                     [1, 2560]                 --\n",
       "â”‚    â””â”€Linear: 2-12                      [1, 3]                    7,683\n",
       "==========================================================================================\n",
       "Total params: 10,693\n",
       "Trainable params: 10,693\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 6.75\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.82\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_cnn, input_size=[1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform_trivial = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform_trivial = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    # transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmented = datasets.ImageFolder(root=train_dir, transform=train_transform_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_augmented = datasets.ImageFolder(root=test_dir, transform=test_transform_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataloader_augmented \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(dataset\u001b[38;5;241m=\u001b[39mtrain_data_augmented, num_workers\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mcpu_count(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader_augmented = DataLoader(dataset=train_data_augmented, num_workers=os.cpu_count(), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_dataloader_augmented \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(dataset\u001b[38;5;241m=\u001b[39mtest_data_augmented, num_workers\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mcpu_count(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataloader_augmented = DataLoader(dataset=test_data_augmented, num_workers=os.cpu_count(), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2/04-pizza-dad.jpeg already exists, skipping download...\n"
     ]
    }
   ],
   "source": [
    "#Predictions with custom image\n",
    "\n",
    "# Download custom image\n",
    "import requests\n",
    "\n",
    "# Setup custom image path\n",
    "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
    "\n",
    "# Download the image if it doesn't already exist\n",
    "if not custom_image_path.is_file():\n",
    "  with open(custom_image_path, \"wb\") as f:\n",
    "    # When downloading from GitHub, need to use the \"raw\" file link\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
    "    print(f\"Downloading {custom_image_path}...\")\n",
    "    f.write(request.content)\n",
    "else:\n",
    "  print(f\"{custom_image_path} already exists, skipping download...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_path_uint8 = torchvision.io.read_image(str(custom_image_path)).type(torch.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
